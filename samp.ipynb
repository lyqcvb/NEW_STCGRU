{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nolds\n",
    "\n",
    "def multiscale_entropy(data, scales=20):\n",
    "    \"\"\"\n",
    "    计算多尺度熵，将长度为 2500 的时间序列转化为 20 个熵值。\n",
    "    \"\"\"\n",
    "    mse_values = []\n",
    "    for tau in range(1, scales + 1):\n",
    "        # 生成当前尺度下的降采样序列\n",
    "        coarse_grained_series = np.array([np.mean(data[i:i + tau]) for i in range(0, len(data) - tau + 1, tau)])\n",
    "        \n",
    "        # 计算该尺度的样本熵\n",
    "        if len(coarse_grained_series) > 2:  # 样本熵要求序列长度足够长\n",
    "            mse_value = nolds.sampen(coarse_grained_series)\n",
    "            mse_values.append(mse_value)\n",
    "        else:\n",
    "            mse_values.append(np.nan)  # 如果降采样序列太短，记录 NaN\n",
    "    return mse_values\n",
    "compressed_data = np.zeros((5643, 43, 20))\n",
    "\n",
    "# 对每个样本和每个通道计算多尺度熵\n",
    "for sample in range(5643):\n",
    "    for channel in range(43):\n",
    "        # 提取单个通道的时间序列\n",
    "        time_series = original_data[sample, channel, :]\n",
    "        # 计算多尺度熵并存储到新的矩阵中\n",
    "        compressed_data[sample, channel, :] = multiscale_entropy(time_series, scales=20)\n",
    "        print(f\"计算完成第 {sample} 个样本的第 {channel} 个通道\")\n",
    "\n",
    "print(\"计算完成的多尺度熵数据形状：\", compressed_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import nolds\n",
    "\n",
    "def multiscale_entropy(data, scales=20):\n",
    "    \"\"\"\n",
    "    计算多尺度熵，将长度为 2500 的时间序列转化为 20 个熵值。\n",
    "    \"\"\"\n",
    "    mse_values = []\n",
    "    for tau in range(1, scales + 1):\n",
    "        # 使用 torch 的张量操作进行降采样\n",
    "        coarse_grained_series = torch.stack([data[i:i + tau].mean() for i in range(0, len(data) - tau + 1, tau)])\n",
    "        \n",
    "        # 将结果转换为 numpy 以计算样本熵\n",
    "        coarse_grained_series = coarse_grained_series.cpu().numpy()  # 确保数据在 CPU 上\n",
    "        if len(coarse_grained_series) > 2:\n",
    "            mse_value = nolds.sampen(coarse_grained_series)\n",
    "            mse_values.append(mse_value)\n",
    "        else:\n",
    "            mse_values.append(np.nan)\n",
    "    return mse_values\n",
    "\n",
    "# 将数据转换为 torch tensor 并将其移到 GPU 上\n",
    "original_data = torch.tensor(original_data, dtype=torch.float32).to(\"cuda\")\n",
    "compressed_data = torch.zeros((5643, 43, 20), device=\"cuda\")\n",
    "\n",
    "# 对每个样本和每个通道并行计算多尺度熵\n",
    "for sample in range(5643):\n",
    "    for channel in range(43):\n",
    "        # 提取单个通道的时间序列\n",
    "        time_series = original_data[sample, channel, :]\n",
    "        # 将时间序列传入多尺度熵函数\n",
    "        mse_values = multiscale_entropy(time_series, scales=20)\n",
    "        # 将结果存储在新张量中\n",
    "        compressed_data[sample, channel, :] = torch.tensor(mse_values, device=\"cuda\")\n",
    "        print(f\"计算完成第 {sample} 个样本的第 {channel} 个通道\")\n",
    "\n",
    "# 将结果转回 CPU 并转换为 numpy 格式\n",
    "compressed_data = compressed_data.cpu().numpy()\n",
    "print(\"计算完成的多尺度熵数据形状：\", compressed_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "total_folds = 10\n",
    "train_indices, test_indices = dl.Split_Sets(total_folds, EEG_crop)\n",
    "# Ensure output directories exist\n",
    "ensure_dir(\"EEG_Augemnted_Data/TrainData\")\n",
    "ensure_dir(\"EEG_Augemnted_Data/ValidData\")\n",
    "ensure_dir(\"EEG_Augemnted_Data/TestData\")\n",
    "kf = KFold(n_splits=10)\n",
    "seed = 34  # 设定随机种子\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(SampleEn_EEG)):\n",
    "    train_data, test_data = SampleEn_EEG[train_index], SampleEn_EEG[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # 进一步划分训练集和验证集\n",
    "    train_data_split, valid_data_split, train_labels_split, valid_labels_split = train_test_split(\n",
    "        train_data, train_labels, test_size=0.1, random_state=seed, stratify=train_labels\n",
    "    )\n",
    "    # print(train_data_split.shape,train_labels_split.shape,valid_data_split.shape,valid_labels_split.shape)\n",
    "\n",
    "    # 转换为 PyTorch 张量\n",
    "    train_data_split = torch.tensor(train_data_split, dtype=torch.float32)\n",
    "    valid_data_split = torch.tensor(valid_data_split, dtype=torch.float32)\n",
    "    train_labels_split = torch.tensor(train_labels_split, dtype=torch.long)\n",
    "    valid_labels_split = torch.tensor(valid_labels_split, dtype=torch.long)\n",
    "\n",
    "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "    # 创建TensorDatasets\n",
    "    train_dataset = TensorDataset(train_data_split, train_labels_split)\n",
    "    valid_dataset = TensorDataset(valid_data_split, valid_labels_split)\n",
    "    test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "    # 保存数据和标签\n",
    "    torch.save(train_dataset, f\"EEG_Augemnted_Data/TrainData/train_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "    torch.save(valid_dataset, f\"EEG_Augemnted_Data/ValidData/valid_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "    torch.save(test_dataset, f\"EEG_Augemnted_Data/TestData/test_data_{fold + 1}_fold_with_seed_{seed}.pth.pth\")\n",
    "    logging.info(f\"Fold {fold + 1} data saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 计算多样本熵 (MSE)\n",
    "def multi_scale_entropy(x, max_scale, m=2, r=0.2):\n",
    "    mse = []\n",
    "    for scale in range(1, max_scale + 1):\n",
    "        # 对信号进行下采样\n",
    "        x_rescaled = x[::scale]\n",
    "        # 计算样本熵\n",
    "        mse.append(nolds.sampen(x_rescaled, m, r*np.std(x_rescaled)))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def calculate_mse_features(data,scale=20,m=2, r=0.2):\n",
    "    mse_all_channels = []\n",
    "    n_channels = data.shape[0]\n",
    "    \n",
    "    # 计算每个通道的 PSD\n",
    "    for i in range(n_channels):\n",
    "        mse = multi_scale_entropy(data[i,:],scale,m,r)\n",
    "        mse_all_channels.append(mse)\n",
    "\n",
    "    mse_df = pd.DataFrame(mse_all_channels)\n",
    "    mse_df.columns = [f'scale_{i+1}' for i in range(scale)]\n",
    "    mse_df['Channel'] = np.arange(1, 20) \n",
    "    mse_df = mse_df.set_index('Channel')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
