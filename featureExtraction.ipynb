{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import nolds\n",
    "from scipy.signal import welch\n",
    "import mne \n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from scipy.stats import entropy\n",
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时域特征计算\n",
    "def calculate_time_domain_features(data):\n",
    "    features = {}\n",
    "    features['mean'] = np.mean(data, axis=1)\n",
    "    features['std'] = np.std(data, axis=1)\n",
    "    features['skew'] = stats.skew(data, axis=1)\n",
    "    features['kurtosis'] = stats.kurtosis(data, axis=1)\n",
    "    time_df = pd.DataFrame(features)\n",
    "    time_df['Channel'] = np.arange(1, 20) \n",
    "    time_df = time_df.set_index('Channel')\n",
    "    return time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 频域特征计算\n",
    "def calculate_psd_features(data, fs=500):\n",
    "    psd_all_channels = []\n",
    "    n_channels = data.shape[0]\n",
    "    \n",
    "    # 计算每个通道的 PSD\n",
    "    for i in range(n_channels):\n",
    "        f, Pxx = welch(data[i, :], fs=fs, nperseg=512)  # 使用Welch方法计算功率谱密度\n",
    "        \n",
    "        # 找到频率在 0.5 到 32 Hz 之间的索引\n",
    "        freq_range = (f >= 0.5) & (f <= 32)\n",
    "        # 提取相应频率和功率谱密度值\n",
    "        Pxx_filtered = Pxx[freq_range]\n",
    "        psd_all_channels.append(Pxx_filtered)\n",
    "\n",
    "    # 创建 DataFrame\n",
    "    psd_df = pd.DataFrame(psd_all_channels)\n",
    "    \n",
    "    # 为列名生成频率标签\n",
    "    freq_labels = [f'{freq:.1f}_hz' for freq in f[freq_range]]\n",
    "    psd_df.columns = freq_labels\n",
    "    \n",
    "    # 添加通道列并设置为索引\n",
    "    psd_df['Channel'] = np.arange(1, n_channels + 1)\n",
    "    psd_df = psd_df.set_index('Channel')\n",
    "\n",
    "    return psd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_permutation_entropy(data, order=3, delay=1):\n",
    "\n",
    "    pe_all_channels = []\n",
    "    n_channels = data.shape[0]\n",
    "    \n",
    "    # 计算每个通道的 PE\n",
    "    for i in range(n_channels):\n",
    "        # Step 3: Extract subsequences and sort them\n",
    "        n = len(data[i])\n",
    "        time_series = data[i]\n",
    "        permutations = np.array([np.argsort(np.take(time_series, list(range(j, j + order * delay, delay)), mode='wrap')) for j in range(n - (order - 1) * delay)])\n",
    "        # Step 4: Count occurrences of each permutation\n",
    "        counts = np.array([len(np.where(permutations == p)[0]) for p in set(tuple(x) for x in permutations)])\n",
    "        # Normalize to get probabilities\n",
    "        probabilities = counts / float(sum(counts))\n",
    "        # Step 5: Calculate entropy\n",
    "        pe = entropy(probabilities)\n",
    "        pe_all_channels.append(pe)\n",
    "    pe_df = pd.DataFrame(pe_all_channels)\n",
    "    pe_df['Channel'] = np.arange(1, 20) \n",
    "    pe_df = pe_df.set_index('Channel')\n",
    "    return pe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature(file_paths,type,base_dir):\n",
    "    for i, file in enumerate(file_paths):\n",
    "        # try:\n",
    "            # raw = mne.io.read_raw_edf(file, preload=True, encoding='latin1',verbose='Warning')\n",
    "            # data = raw.get_data()[0:19]\n",
    "            data = np.array(pd.read_csv(file))[:,1:]\n",
    "            # 计算时域特征\n",
    "            feature = calculate_psd_features(data)\n",
    "            file_name = file[16:19]\n",
    "            name = file[20:]\n",
    "            if file_name[-1]=='\\\\':\n",
    "                file_name=file_name[0:len(file_name)-1]\n",
    "                name = file[19:]\n",
    "            if(type == 0):\n",
    "                dir = base_dir+\"\\\\PSD\\\\认知正常\\\\\"+file_name+'\\\\'\n",
    "                ensure_dir(dir)\n",
    "                file_path = dir+name\n",
    "                feature.to_csv(file_path)\n",
    "            else:\n",
    "                dir = base_dir+\"\\\\PSD\\\\认知障碍\\\\\"+file_name+'\\\\'\n",
    "                ensure_dir(dir)\n",
    "                file_path = dir+name\n",
    "                feature.to_csv(file_path)\n",
    "            print(i , \" has been processed\")\n",
    "        # except Exception as e:\n",
    "        #     logging.error(f\"Error processing file {file}: {e}\")\n",
    "        #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 忽略 RuntimeWarning 警告\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "# 定义文件夹路径\n",
    "base_dir = '糖尿病数据ICA分段'\n",
    "normal_dir = os.path.join(base_dir, '认知正常')\n",
    "impaired_dir = os.path.join(base_dir, '认知障碍')\n",
    "\n",
    "# 获取所有的文件路径\n",
    "\n",
    "\n",
    "normal_files_names = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) ]\n",
    "normal_files = [os.path.join(x, f) for x in  normal_files_names for f in os.listdir(x ) if f.endswith('.csv')]\n",
    "impaired_files_names = [os.path.join(impaired_dir, f) for f in os.listdir(impaired_dir)]\n",
    "impaired_files = [os.path.join(x, f) for x in  impaired_files_names for f in os.listdir(x ) if f.endswith('.csv')]\n",
    "save_dir = \"糖尿病数据特征\"\n",
    "save_feature(normal_files,0,save_dir)\n",
    "save_feature(impaired_files,1,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6383, 7743)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_files),len(impaired_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'于桂荣'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example=impaired_files[0]\n",
    "example[16:19]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
