{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:43:09.750984Z",
     "start_time": "2024-12-03T02:43:06.095310Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from matplotlib import axis\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import math\n",
    "import mne\n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import traingset as dl  # Ensure this module contains necessary utility functions\n",
    "import logging\n",
    "from mne.preprocessing import ICA\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用 GPU\n",
    "seed = 42\n",
    "dl.seed_everything(seed)\n",
    "# EEG data parameters\n",
    "duration = 1000\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "from itertools import combinations\n",
    "\n",
    "# 初始脑区定义\n",
    "regions = {\n",
    "    \"prefrontal\": [0, 1, 2, 3, 10, 11, 16],\n",
    "    \"central\": [4, 5, 17],\n",
    "    \"temporal\": [12, 13, 14, 15],\n",
    "    \"parietal\": [6, 7, 18],\n",
    "    \"occipital\": [8, 9]\n",
    "}\n",
    "\n",
    "# 自动生成多脑区组合\n",
    "def generate_combinations(regions, sizes):\n",
    "    combined_regions = {}\n",
    "    region_names = list(regions.keys())\n",
    "\n",
    "    # 遍历指定组合大小\n",
    "    for size in sizes:\n",
    "        for combination in combinations(region_names, size):\n",
    "            combined_name = \"_\".join(combination)  # 组合名称\n",
    "            combined_indices = sorted(set().union(*(regions[region] for region in combination)))  # 合并去重\n",
    "            combined_regions[combined_name] = combined_indices\n",
    "\n",
    "    return combined_regions\n",
    "\n",
    "# 生成所有二、三、四脑区组合\n",
    "regions = generate_combinations(regions, sizes=[1,2, 3, 4,5])\n",
    "# 动态获取变量值\n",
    "partition = \"prefrontal_central_temporal_parietal_occipital\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importAndCropData(file_set, duration, labels,partition):\n",
    "    EEG_list = []\n",
    "    label = []\n",
    "    name = []\n",
    "    for i, file in enumerate(file_set):\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(file[0], preload=True, encoding='latin1',verbose='Warning')\n",
    "            local_name = file[1]\n",
    "            data = raw.get_data()[0:19]\n",
    "            data = data[partition]\n",
    "            if data.shape[1] > duration:\n",
    "                epochs = data.shape[1] // duration\n",
    "                data_crop = data[:,0:epochs*duration]\n",
    "            else:\n",
    "                continue\n",
    "            label += [labels[i]] * epochs\n",
    "            name  += [local_name] * epochs\n",
    "            channels = len(partition)\n",
    "            data_new = data_crop.reshape(channels, -1, duration).transpose(1, 0, 2)\n",
    "            EEG_list.append(data_new)\n",
    "            logging.info(f\"Processed file {file}: {epochs} epochs\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing file {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not EEG_list:\n",
    "        raise ValueError(\"No data was loaded. Please check the file paths and formats.\")\n",
    "    \n",
    "    EEG = np.concatenate(EEG_list)\n",
    "    label = np.array(label)\n",
    "    name = np.array(name)\n",
    "    logging.info(f\"Total epochs: {EEG.shape[0]}, Normal: {np.sum(label == 1)}, \"\n",
    "            f\"MCI: {np.sum(label == 0)}\")\n",
    "    return EEG,label,name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "# 忽略 RuntimeWarning 警告\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "# 定义文件夹路径\n",
    "base_dir = '糖尿病认知障碍与对照脑电数据'\n",
    "normal_dir = os.path.join(base_dir, '认知正常')\n",
    "impaired_dir = os.path.join(base_dir, '认知障碍')\n",
    "\n",
    "# 获取所有的文件路径\n",
    "normal_files = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) if f.endswith('.edf')]\n",
    "impaired_files = [os.path.join(impaired_dir, f) for f in os.listdir(impaired_dir) if f.endswith('.edf')]\n",
    "\n",
    "# 获取所有的文件路径和文件名（以二元组存储）\n",
    "normal_files = [(os.path.join(normal_dir, f), f[:-4]) for f in os.listdir(normal_dir) if f.endswith('.edf')]\n",
    "impaired_files = [(os.path.join(impaired_dir, f), f[:-4]) for f in os.listdir(impaired_dir) if f.endswith('.edf')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = normal_files + impaired_files\n",
    "label_single = np.concatenate([np.ones(len(impaired_files)), np.zeros(len(normal_files))],axis=0)\n",
    "# 将 all_files 和 label_single 中的元素按相同顺序打乱\n",
    "combined = list(zip(all_files, label_single))\n",
    "random.shuffle(combined)\n",
    "all_files[:], label_single[:] = zip(*combined)\n",
    "original_data,labels,name = importAndCropData(all_files, duration, label_single,regions[partition])\n",
    "final_data =original_data.reshape(original_data.shape[0],1,original_data.shape[1],original_data.shape[2])\n",
    "print(len(original_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Ensure output directories exist\n",
    "ensure_dir(\"EEGData/\"+str(partition)+\"/TrainData\")\n",
    "ensure_dir(\"EEGData/\"+str(partition)+\"/ValidData\")\n",
    "ensure_dir(\"EEGData/\"+str(partition)+\"/TestData\")\n",
    "\n",
    "# 假设 final_data, labels 是已有的 numpy 数组\n",
    "# final_data: shape = (samples, 时间长度)\n",
    "# labels: shape = (samples, 1)，每个样本的标签为 0 或 1\n",
    "\n",
    "# 将 labels 从二维转换为一维\n",
    "labels = labels.reshape(-1)\n",
    "\n",
    "# 创建 StratifiedKFold 对象，指定 10 折交叉验证\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# 遍历每一折\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(final_data, labels)):\n",
    "    try:\n",
    "        train_data, test_data = final_data[train_idx], final_data[val_idx]\n",
    "        train_labels, test_labels = labels[train_idx], labels[val_idx]\n",
    "        \n",
    "        train_data_split, valid_data_split, train_labels_split, valid_labels_split = train_test_split(\n",
    "                train_data, train_labels, test_size=0.1, random_state=seed, stratify=train_labels\n",
    "            )\n",
    "        # print(train_data_split.shape,train_labels_split.shape,valid_data_split.shape,valid_labels_split.shape)\n",
    "        # Convert to PyTorch tensors\n",
    "        train_tensor = torch.from_numpy(train_data_split).float() # (samples, channels, duration)\n",
    "        train_labels_tensor = torch.from_numpy(train_labels_split).long()\n",
    "\n",
    "        valid_tensor = torch.from_numpy(valid_data_split).float()\n",
    "        valid_labels_tensor = torch.from_numpy(valid_labels_split).long()\n",
    "\n",
    "        test_tensor = torch.from_numpy(test_data).float()\n",
    "        test_labels_tensor = torch.from_numpy(test_labels).long()\n",
    "\n",
    "        # Create TensorDatasets\n",
    "        train_dataset = TensorDataset(train_tensor, train_labels_tensor)\n",
    "        valid_dataset = TensorDataset(valid_tensor, valid_labels_tensor)\n",
    "        test_dataset = TensorDataset(test_tensor, test_labels_tensor)\n",
    "\n",
    "        # Save datasets\n",
    "        torch.save(train_dataset, \"EEGData/\"+str(partition)+f\"/TrainData/train_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "        torch.save(valid_dataset, \"EEGData/\"+str(partition)+f\"/ValidData/valid_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "        torch.save(test_dataset, \"EEGData/\"+str(partition)+f\"/TestData/test_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "\n",
    "        logging.info(f\"Fold {fold + 1} data saved successfully.\")\n",
    "            # 转换 y_train 和 y_val 为整数类型\n",
    "        y_train = train_labels_split.astype(int)\n",
    "        y_val = valid_labels_split.astype(int)\n",
    "        y_test = test_labels.astype(int)\n",
    "        # 输出当前折的训练集和验证集和测试集大小\n",
    "        print(f\"Fold {fold+1}:\")\n",
    "        print(f\"  训练集大小: {y_train.shape}, 验证集大小: {y_val.shape}, 测试集大小: {y_test.shape}\")\n",
    "        print(f\"  训练集标签分布: {np.bincount(y_train)}\")\n",
    "        print(f\"  验证集标签分布: {np.bincount(y_val)}\")\n",
    "        print(f\"  测试集标签分布: {np.bincount(y_test)}\\n\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing fold {fold + 1}: {e}\")\n",
    "\n",
    "print(\"存储区:\",partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import logging\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "# from torch.utils.data import TensorDataset\n",
    "# from collections import defaultdict  # 导入 defaultdict\n",
    "\n",
    "# # 确保输出目录存在\n",
    "# def ensure_dir(directory):\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "\n",
    "# # 假设 final_data, labels, name 是已有的 numpy 数组\n",
    "# # final_data: shape = (samples, 时间长度)\n",
    "# # labels: shape = (samples, 1)，每个样本的标签为 0 或 1\n",
    "# # name: shape = (samples, 1)，每个样本的患者名称\n",
    "# # 将 labels 从二维转换为一维\n",
    "# labels = labels.reshape(-1)\n",
    "\n",
    "# # 获取患者的唯一名称，并为每个患者对应的样本构建索引\n",
    "# unique_patients = np.unique(name)\n",
    "\n",
    "# # 为每个患者创建一个列表，存储该患者对应的所有样本的索引\n",
    "# patient_indices = defaultdict(list)\n",
    "# for idx, patient in enumerate(name):\n",
    "#     patient_indices[patient].append(idx)\n",
    "\n",
    "# # 创建 StratifiedKFold 对象，指定 10 折交叉验证\n",
    "# kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# # 确保输出目录存在\n",
    "# ensure_dir(f\"EEGDataPatient/{partition}/TrainData\")\n",
    "# ensure_dir(f\"EEGDataPatient/{partition}/ValidData\")\n",
    "# ensure_dir(f\"EEGDataPatient/{partition}/TestData\")\n",
    "\n",
    "# # 遍历每一折\n",
    "# for fold, (train_patients, val_patients) in enumerate(kf.split(unique_patients, [labels[name == patient][0] for patient in unique_patients])):\n",
    "#     try:\n",
    "#         # 将患者的索引合并成训练集和验证集\n",
    "#         train_indices = []\n",
    "#         val_indices = []\n",
    "        \n",
    "#         for patient in train_patients:\n",
    "#             train_indices.extend(patient_indices[unique_patients[patient]])\n",
    "        \n",
    "#         for patient in val_patients:\n",
    "#             val_indices.extend(patient_indices[unique_patients[patient]])\n",
    "        \n",
    "#         # 提取训练集和验证集的原始数据和标签\n",
    "#         train_data, val_data = final_data[train_indices], final_data[val_indices]\n",
    "#         train_labels, val_labels = labels[train_indices], labels[val_indices]\n",
    "        \n",
    "#         # 对训练集进行进一步的划分，得到训练集和验证集\n",
    "#         train_data_split, valid_data_split, train_labels_split, valid_labels_split = train_test_split(\n",
    "#             train_data, train_labels, test_size=0.1, random_state=seed, stratify=train_labels\n",
    "#         )\n",
    "        \n",
    "#         # 转换为 PyTorch tensors\n",
    "#         train_tensor = torch.from_numpy(train_data_split).float()\n",
    "#         train_labels_tensor = torch.from_numpy(train_labels_split).long()\n",
    "        \n",
    "#         valid_tensor = torch.from_numpy(valid_data_split).float()\n",
    "#         valid_labels_tensor = torch.from_numpy(valid_labels_split).long()\n",
    "        \n",
    "#         test_tensor = torch.from_numpy(val_data).float()\n",
    "#         test_labels_tensor = torch.from_numpy(val_labels).long()\n",
    "\n",
    "#         # 创建 TensorDatasets\n",
    "#         train_dataset = TensorDataset(train_tensor, train_labels_tensor)\n",
    "#         valid_dataset = TensorDataset(valid_tensor, valid_labels_tensor)\n",
    "#         test_dataset = TensorDataset(test_tensor, test_labels_tensor)\n",
    "\n",
    "#         # 保存数据集\n",
    "#         torch.save(train_dataset, \"EEGDataPatient/\"+str(partition)+f\"/TrainData/train_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "#         torch.save(valid_dataset, \"EEGDataPatient/\"+str(partition)+f\"/ValidData/valid_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "#         torch.save(test_dataset, \"EEGDataPatient/\"+str(partition)+f\"/TestData/test_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "\n",
    "#         logging.info(f\"Fold {fold + 1} data saved successfully.\")\n",
    "        \n",
    "#         # 输出当前折的训练集、验证集和测试集大小\n",
    "#         y_train = train_labels_split.astype(int)\n",
    "#         y_val = valid_labels_split.astype(int)\n",
    "#         y_test = val_labels.astype(int)\n",
    "\n",
    "#         print(f\"Fold {fold + 1}:\")\n",
    "#         print(f\"  训练集大小: {y_train.shape}, 验证集大小: {y_val.shape}, 测试集大小: {y_test.shape}\")\n",
    "#         print(f\"  训练集标签分布: {np.bincount(y_train)}\")\n",
    "#         print(f\"  验证集标签分布: {np.bincount(y_val)}\")\n",
    "#         print(f\"  测试集标签分布: {np.bincount(y_test)}\\n\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error processing fold {fold + 1}: {e}\")\n",
    "\n",
    "# print(f\"存储区: {partition}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
