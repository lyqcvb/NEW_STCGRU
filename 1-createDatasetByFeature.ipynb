{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:43:09.750984Z",
     "start_time": "2024-12-03T02:43:06.095310Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from matplotlib import axis\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import model as dl  # Ensure this module contains necessary utility functions\n",
    "import logging\n",
    "from mne.preprocessing import ICA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    \n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    \n",
    "    return accuracy, sensitivity, specificity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importAndCropData(file_paths, labels,partition):\n",
    "    EEG_list = []\n",
    "    for i, file in enumerate(file_paths):\n",
    "        try:\n",
    "            raw =pd.read_csv(file)\n",
    "            data = np.array(raw)[:,1:]\n",
    "            data = data[partition]\n",
    "            channels = len(partition)\n",
    "            feature = data.shape[1]\n",
    "            data_new = data.reshape(1, channels, feature)\n",
    "            EEG_list.append(data_new)\n",
    "            logging.info(f\"Processed file {file} done\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing file {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not EEG_list:\n",
    "        raise ValueError(\"No data was loaded. Please check the file paths and formats.\")\n",
    "    EEG = np.concatenate(EEG_list)\n",
    "    logging.info(f\"Total epochs: {EEG.shape[0]}, Normal: {np.sum(labels == 1)}, \"\n",
    "            f\"MCI: {np.sum(labels == 0)}\")\n",
    "    return EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用 GPU\n",
    "seed = 66\n",
    "dl.seed_everything(seed)\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "# 初始脑区定义\n",
    "regions = {\n",
    "    \"prefrontal\": [0, 1, 2, 3, 10, 11, 16],\n",
    "    \"central\": [4, 5, 17],\n",
    "    \"temporal\": [12, 13, 14, 15],\n",
    "    \"parietal\": [6, 7, 18],\n",
    "    \"occipital\": [8, 9]\n",
    "}\n",
    "\n",
    "# 自动生成多脑区组合\n",
    "def generate_combinations(regions, sizes):\n",
    "    combined_regions = {}\n",
    "    region_names = list(regions.keys())\n",
    "\n",
    "    # 遍历指定组合大小\n",
    "    for size in sizes:\n",
    "        for combination in combinations(region_names, size):\n",
    "            combined_name = \"_\".join(combination)  # 组合名称\n",
    "            combined_indices = sorted(set().union(*(regions[region] for region in combination)))  # 合并去重\n",
    "            combined_regions[combined_name] = combined_indices\n",
    "\n",
    "    return combined_regions\n",
    "\n",
    "# 生成所有二、三、四脑区组合\n",
    "regions = generate_combinations(regions, sizes=[1,2,3,4,5])\n",
    "# 动态获取变量值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "# 忽略 RuntimeWarning 警告\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "# 定义文件夹路径\n",
    "base_dir = '糖尿病数据特征'\n",
    "normal_dir = os.path.join(base_dir, 'PSD\\\\认知正常\\\\')\n",
    "impaired_dir = os.path.join(base_dir, 'PSD\\\\认知障碍\\\\')\n",
    "partition = \"occipital\"\n",
    "# 获取所有的文件路径\n",
    "\n",
    "normal_files_names = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) ]\n",
    "normal_files = [os.path.join(x, f) for x in  normal_files_names for f in os.listdir(x ) if f.endswith('.csv')]\n",
    "impaired_files_names = [os.path.join(impaired_dir, f) for f in os.listdir(impaired_dir)]\n",
    "impaired_files = [os.path.join(x, f) for x in  impaired_files_names for f in os.listdir(x ) if f.endswith('.csv')]\n",
    "\n",
    "all_files = normal_files + impaired_files\n",
    "labels = np.concatenate([np.zeros(len(normal_files)),np.ones(len(impaired_files))],axis=0)\n",
    "\n",
    "\n",
    "# 将 all_files 和 label_single 中的元素按相同顺序打乱\n",
    "combined = list(zip(all_files, labels))\n",
    "random.shuffle(combined)\n",
    "all_files[:], labels[:] = zip(*combined)\n",
    "\n",
    "\n",
    "original_data = importAndCropData(all_files,labels,regions[partition])\n",
    "final_data =original_data.reshape(original_data.shape[0],1,original_data.shape[1],original_data.shape[2])\n",
    "# prefrontal_data = importAndCropData(all_files, duration,labels,regions[\"prefrontal\"])\n",
    "# central_data = importAndCropData(all_files, duration,labels,regions[\"central\"])\n",
    "# temporal_data = importAndCropData(all_files, duration,labels,regions[\"temporal\"])\n",
    "# parietal_data = importAndCropData(all_files, duration,labels,regions[\"parietal\"])\n",
    "# occipital_data = importAndCropData(all_files, duration,labels,regions[\"occipital\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Ensure output directories exist\n",
    "ensure_dir(\"EEGDataFeatured/\"+str(partition)+\"/TrainData\")\n",
    "ensure_dir(\"EEGDataFeatured/\"+str(partition)+\"/ValidData\")\n",
    "ensure_dir(\"EEGDataFeatured/\"+str(partition)+\"/TestData\")\n",
    "\n",
    "# 假设 final_data, labels 是已有的 numpy 数组\n",
    "# final_data: shape = (samples, 时间长度)\n",
    "# labels: shape = (samples, 1)，每个样本的标签为 0 或 1\n",
    "\n",
    "# 将 labels 从二维转换为一维\n",
    "labels = labels.reshape(-1)\n",
    "\n",
    "# 创建 StratifiedKFold 对象，指定 10 折交叉验证\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# 遍历每一折\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(final_data, labels)):\n",
    "    try:\n",
    "        train_data, test_data = final_data[train_idx], final_data[val_idx]\n",
    "        train_labels, test_labels = labels[train_idx], labels[val_idx]\n",
    "        \n",
    "        train_data_split, valid_data_split, train_labels_split, valid_labels_split = train_test_split(\n",
    "                train_data, train_labels, test_size=0.1, random_state=seed, stratify=train_labels\n",
    "            )\n",
    "        # print(train_data_split.shape,train_labels_split.shape,valid_data_split.shape,valid_labels_split.shape)\n",
    "        # Convert to PyTorch tensors\n",
    "        train_tensor = torch.from_numpy(train_data_split).float() # (samples, channels, duration)\n",
    "        train_labels_tensor = torch.from_numpy(train_labels_split).long()\n",
    "\n",
    "        valid_tensor = torch.from_numpy(valid_data_split).float()\n",
    "        valid_labels_tensor = torch.from_numpy(valid_labels_split).long()\n",
    "\n",
    "        test_tensor = torch.from_numpy(test_data).float()\n",
    "        test_labels_tensor = torch.from_numpy(test_labels).long()\n",
    "\n",
    "        # Create TensorDatasets\n",
    "        train_dataset = TensorDataset(train_tensor, train_labels_tensor)\n",
    "        valid_dataset = TensorDataset(valid_tensor, valid_labels_tensor)\n",
    "        test_dataset = TensorDataset(test_tensor, test_labels_tensor)\n",
    "\n",
    "        # Save datasets\n",
    "        torch.save(train_dataset, \"EEGDataFeatured/\"+str(partition)+f\"/TrainData/train_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "        torch.save(valid_dataset, \"EEGDataFeatured/\"+str(partition)+f\"/ValidData/valid_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "        torch.save(test_dataset, \"EEGDataFeatured/\"+str(partition)+f\"/TestData/test_data_{fold + 1}_fold_with_seed_{seed}.pth\")\n",
    "\n",
    "        logging.info(f\"Fold {fold + 1} data saved successfully.\")\n",
    "            # 转换 y_train 和 y_val 为整数类型\n",
    "        y_train = train_labels_split.astype(int)\n",
    "        y_val = valid_labels_split.astype(int)\n",
    "        y_test = test_labels.astype(int)\n",
    "        # 输出当前折的训练集和验证集和测试集大小\n",
    "        print(f\"Fold {fold+1}:\")\n",
    "        print(f\"  训练集大小: {y_train.shape}, 验证集大小: {y_val.shape}, 测试集大小: {y_test.shape}\")\n",
    "        print(f\"  训练集标签分布: {np.bincount(y_train)}\")\n",
    "        print(f\"  验证集标签分布: {np.bincount(y_val)}\")\n",
    "        print(f\"  测试集标签分布: {np.bincount(y_test)}\\n\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing fold {fold + 1}: {e}\")\n",
    "\n",
    "print(\"存储区:\",partition)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
